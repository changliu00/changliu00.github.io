@InProceedings{liu2019understanding_b,
  title = 	 {Understanding {MCMC} Dynamics as Flows on the {W}asserstein Space},
  author = 	 {Liu, Chang and Zhuo, Jingwei and Zhu, Jun},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {4093--4103},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/liu19j/liu19j.pdf},
  url = 	 {http://proceedings.mlr.press/v97/liu19j.html},
  organization={IMLS},
  abstract = 	 {It is known that the Langevin dynamics used in MCMC is the gradient flow of the KL divergence on the Wasserstein space, which helps convergence analysis and inspires recent particle-based variational inference methods (ParVIs). But no more MCMC dynamics is understood in this way. In this work, by developing novel concepts, we propose a theoretical framework that recognizes a general MCMC dynamics as the fiber-gradient Hamiltonian flow on the Wasserstein space of a fiber-Riemannian Poisson manifold. The "conservation + convergence" structure of the flow gives a clear picture on the behavior of general MCMC dynamics. The framework also enables ParVI simulation of MCMC dynamics, which enriches the ParVI family with more efficient dynamics, and also adapts ParVI advantages to MCMCs. We develop two ParVI methods for a particular MCMC dynamics and demonstrate the benefits in experiments.}
}

